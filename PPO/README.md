Still figuring out what PPO is and using this dir to figure things out. 

We have a scalar reward system that will use the difference in sycophancy between the top Reddit response and our model's response. Using GPT4o as the judge, that judge code exists in the evaluate_responses dir. 

We need output logits from an SFT'd LLM. 
